{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from network.conv_node import NODE\n",
    "from misc import *\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 모델 로드\n",
    "model = NODE(device, (3, 400, 600), 32, augment_dim=0, time_dependent=True, adjoint=True)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(f'/home/lbw/CLODE/pth/pth/lowlight.pth', weights_only=True), strict=False)\n",
    "\n",
    "# 결과 저장을 위한 디렉토리 생성\n",
    "cache_dir = Path('/home/lbw/CLODE/eval_CLODE_pkl/LOL_eval')\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# eval15 데이터 불러오기\n",
    "eval_path = Path('/home/lbw/data/eval15')\n",
    "eval_images = [f for f in sorted(os.listdir(eval_path / 'low')) if f.lower().endswith('.png')]\n",
    "\n",
    "def load_eval_image(idx):\n",
    "    img_name = eval_images[idx]\n",
    "    lq_img = image_tensor(eval_path / 'low' / img_name)\n",
    "    lq_img_224 = image_tensor(eval_path / 'low' / img_name, size=(224, 224))\n",
    "    gt_img = image_tensor(eval_path / 'high' / img_name)\n",
    "    \n",
    "    return lq_img.to(device), gt_img.to(device), img_name, lq_img_224.to(device)\n",
    "\n",
    "# T 값들 설정\n",
    "T_values = np.linspace(2, 5, 30)\n",
    "T_tensors = [torch.tensor([0, T]).float().cuda() for T in T_values]\n",
    "\n",
    "# 이미지별 결과 저장용 딕셔너리\n",
    "all_results = {}\n",
    "\n",
    "# 이미지별 NODE 계산 및 결과 저장\n",
    "for idx in tqdm(range(len(eval_images))):\n",
    "    lq_img, gt_img, img_name, lq_img_224 = load_eval_image(idx)\n",
    "    \n",
    "    # 결과 저장용 딕셔너리\n",
    "    image_results = {\n",
    "        'img_name': img_name,\n",
    "        'lq_img': lq_img.cpu(),\n",
    "        'gt_img': gt_img.cpu(),\n",
    "        'lq_img_224': lq_img_224.cpu(),\n",
    "        'T_values': T_values,\n",
    "        'preds': [],\n",
    "        'psnrs': [],\n",
    "        'ssims': []\n",
    "    }\n",
    "    \n",
    "    # 모든 T에 대한 예측 수행\n",
    "    with torch.no_grad():\n",
    "        for T_tensor in T_tensors:\n",
    "            pred = model(lq_img, T_tensor, inference=True)['output'][0]\n",
    "            # 결과 저장 (CPU로 이동)\n",
    "            image_results['preds'].append(pred.cpu())\n",
    "            psnr = calculate_psnr(pred, gt_img).item()\n",
    "            image_results['psnrs'].append(psnr)\n",
    "            # SSIM 계산\n",
    "            ssim_value = calculate_ssim(pred, gt_img)\n",
    "            image_results['ssims'].append(ssim_value)\n",
    "    \n",
    "    # PSNR 기반 best_T 찾기\n",
    "    best_T_idx = np.argmax(image_results['psnrs'])\n",
    "    image_results['best_T'] = T_values[best_T_idx]\n",
    "    image_results['best_T_idx'] = best_T_idx\n",
    "    image_results['best_psnr'] = image_results['psnrs'][best_T_idx]\n",
    "    image_results['best_ssim'] = image_results['ssims'][best_T_idx]\n",
    "    \n",
    "    # 결과 저장\n",
    "    all_results[idx] = image_results\n",
    "    \n",
    "    # 메모리 관리를 위해 중간 저장\n",
    "    if idx % 5 == 0 or idx == len(eval_images) - 1:\n",
    "        with open(cache_dir / f'model_results_batch_{idx//5}.pkl', 'wb') as f:\n",
    "            pickle.dump({k: all_results[k] for k in all_results if k//5 == idx//5}, f)\n",
    "        \n",
    "        # 메모리 확보\n",
    "        if idx % 5 == 4:\n",
    "            for k in list(all_results.keys()):\n",
    "                if k//5 == (idx//5 - 1):\n",
    "                    del all_results[k]\n",
    "\n",
    "# 모든 결과의 요약 통계 저장\n",
    "summary = {\n",
    "    'image_count': len(eval_images),\n",
    "    'T_values': T_values.tolist(),\n",
    "    'best_Ts': [all_results[idx]['best_T'] for idx in range(len(eval_images)) if idx in all_results],\n",
    "    'best_psnrs': [all_results[idx]['best_psnr'] for idx in range(len(eval_images)) if idx in all_results],\n",
    "    'best_ssims': [all_results[idx]['best_ssim'] for idx in range(len(eval_images)) if idx in all_results],\n",
    "}\n",
    "\n",
    "# 요약 정보 저장\n",
    "with open(cache_dir / 'summary.pkl', 'wb') as f:\n",
    "    pickle.dump(summary, f)\n",
    "\n",
    "print(f\"모든 이미지({len(eval_images)}개)의 처리 결과를 {cache_dir}에 저장했습니다.\")\n",
    "print(f\"이제 regressor만 변경하면서 빠르게 실험할 수 있습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from torchmetrics.multimodal import CLIPImageQualityAssessment\n",
    "from network.clip_regressor import TtoTRegressor\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 결과 저장을 위한 디렉토리 생성\n",
    "results_dir = Path('/home/lbw/CLODE/result_img/CLODE_eval_results_low_feature_score2')\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 캐시된 결과 불러오기\n",
    "cache_dir = Path('/home/lbw/CLODE/cached_results')\n",
    "eval_path = Path('/home/lbw/data/eval15')\n",
    "eval_images = [f for f in sorted(os.listdir(eval_path / 'low')) if f.lower().endswith('.png')]\n",
    "\n",
    "# 요약 정보 불러오기\n",
    "with open(cache_dir / 'summary.pkl', 'rb') as f:\n",
    "    summary = pickle.load(f)\n",
    "\n",
    "T_values = np.array(summary['T_values'])\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "input_dim = 768\n",
    "hidden_dim = 64\n",
    "\n",
    "# 모델 초기화\n",
    "regressor = Regressor(input_dim, 3, hidden_dim).to(device)\n",
    "regressor.eval()\n",
    "regressor.to(device)\n",
    "model_path_name = (model_path / f'att_regression_{best_epoch}.pth')\n",
    "print(model_path_name, input_dim)\n",
    "regressor.load_state_dict(torch.load(model_path_name, map_location=device))\n",
    "\n",
    "# CLIP 설정\n",
    "prompts = ('brightness', 'noisiness', 'quality')\n",
    "clip_metric = CLIPImageQualityAssessment(\n",
    "    model_name_or_path=\"openai/clip-vit-large-patch14\",\n",
    "    prompts=prompts\n",
    ").to(device)\n",
    "\n",
    "clip_vision_encoder = clip_metric.model.vision_model\n",
    "clip_vision_encoder.eval()\n",
    "clip_vision_encoder.to(device)\n",
    "\n",
    "clip_visual_projection = clip_metric.model.visual_projection\n",
    "clip_visual_projection.eval()\n",
    "clip_visual_projection.to(device)\n",
    "\n",
    "def calculate_clip_score(pred, prompts=prompts):    \n",
    "    # 이미 배치 차원이 있는지 확인하고 없으면 추가\n",
    "    if len(pred.shape) == 3:\n",
    "        pred = pred.unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 한 번의 forward pass로 모든 프롬프트에 대한 점수를 계산\n",
    "        scores = clip_metric(pred)\n",
    "        encoder_feature = clip_vision_encoder(pred) \n",
    "        projection = clip_visual_projection(encoder_feature[1]) \n",
    "        \n",
    "        # scores 딕셔너리를 텐서로 변환\n",
    "        scores_tensor = torch.tensor([\n",
    "            scores[prompts[0]].item(),\n",
    "            scores[prompts[1]].item(),\n",
    "            scores[prompts[2]].item()\n",
    "        ], device=device).unsqueeze(0)  \n",
    "        \n",
    "        combined_features = torch.cat([projection, scores_tensor], dim=1)\n",
    "\n",
    "    return combined_features\n",
    "\n",
    "def tensor_to_numpy(tensor):\n",
    "    \"\"\"PyTorch 텐서를 NumPy 배열로 변환합니다.\"\"\"\n",
    "    # GPU -> CPU 이동 및 계산 그래프에서 분리\n",
    "    img = tensor.detach().cpu().numpy()\n",
    "    \n",
    "    # 이미지 형식 변환 (C,H,W) -> (H,W,C)\n",
    "    if img.ndim == 3 and img.shape[0] == 3:\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "    \n",
    "    # 값 범위 조정 [0, 1]\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Regressor 평가용 변수\n",
    "pred_Ts = []\n",
    "pred_psnrs = []\n",
    "pred_ssims = []\n",
    "\n",
    "# 이미지별 결과 불러오고 regressor 평가\n",
    "for idx in tqdm(range(len(eval_images))):\n",
    "    # 이미지의 결과가 어떤 배치 파일에 있는지 계산\n",
    "    batch_idx = idx // 5\n",
    "    \n",
    "    # 배치 파일 로드\n",
    "    with open(cache_dir / f'model_results_batch_{batch_idx}.pkl', 'rb') as f:\n",
    "        batch_results = pickle.load(f)\n",
    "    \n",
    "    # 현재 이미지 결과\n",
    "    img_results = batch_results[idx]\n",
    "    \n",
    "    # 필요한 데이터 추출\n",
    "    lq_img_224 = img_results['lq_img_224'].to(device)\n",
    "    best_T = img_results['best_T']\n",
    "    best_psnr = img_results['best_psnr']\n",
    "    best_ssim = img_results['best_ssim']\n",
    "    psnrs = img_results['psnrs']\n",
    "    ssims = img_results['ssims']\n",
    "    img_name = img_results['img_name']\n",
    "    \n",
    "    # CLIP 점수 계산 및 행렬 구성\n",
    "    clip_feature = calculate_clip_score(lq_img_224)\n",
    "\n",
    "    # Regressor로 T 예측\n",
    "    with torch.no_grad():\n",
    "        pred_T = regressor(clip_feature)\n",
    "        pred_T = pred_T.item()\n",
    "    \n",
    "    # 가장 가까운 T 값 찾기\n",
    "    pred_T_idx = np.argmin(np.abs(T_values - pred_T))\n",
    "    \n",
    "    # 결과 저장\n",
    "    pred_Ts.append(pred_T)\n",
    "    pred_psnrs.append(psnrs[pred_T_idx])\n",
    "    pred_ssims.append(ssims[pred_T_idx])\n",
    "    \n",
    "    # 시각화 (필요한 경우)\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # 원본 저화질 이미지\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(tensor_to_numpy(img_results['lq_img'][0].cpu()))\n",
    "    plt.title(f'Low Quality Image: {img_name}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # 원본 고화질 이미지\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(tensor_to_numpy(img_results['gt_img'][0].cpu()))\n",
    "    plt.title('Ground Truth')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # PSNR 기반 best_T 이미지\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(tensor_to_numpy(img_results['preds'][img_results['best_T_idx']].cpu()))\n",
    "    plt.title(f'NODE Best T={best_T:.2f}, PSNR={best_psnr:.2f}dB, SSIM={best_ssim:.4f}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Regressor 예측 T 이미지\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(tensor_to_numpy(img_results['preds'][pred_T_idx].cpu()))\n",
    "    plt.title(f'Regressor Pred T={pred_T:.2f}, PSNR={psnrs[pred_T_idx]:.2f}dB, SSIM={ssims[pred_T_idx]:.4f}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # 결과 저장\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir / f'{img_name.split(\".\")[0]}_compare.png')\n",
    "    plt.close()\n",
    "\n",
    "# 통계 정보 계산 (전체 이미지에 대해)\n",
    "best_Ts = summary['best_Ts']\n",
    "best_psnrs = summary['best_psnrs']\n",
    "best_ssims = summary['best_ssims']\n",
    "\n",
    "print(\"모든 이미지 처리 완료!\")\n",
    "\n",
    "# best_Ts와 pred_Ts를 하나의 플롯에 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(best_Ts, label='Best Ts (PSNR-based)', marker='o')\n",
    "plt.plot(pred_Ts, label='Predicted Ts (Regressor-based)', marker='x')\n",
    "plt.xlabel('Image Index')\n",
    "plt.ylabel('T Values')\n",
    "plt.title('Comparison of Best Ts and Predicted Ts')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(results_dir / 'best_vs_pred_Ts.png')\n",
    "plt.show()\n",
    "\n",
    "# 결과 비교\n",
    "print(f\"Best T PSNR 평균: {np.mean(best_psnrs):.2f}dB\")\n",
    "print(f\"Predicted T PSNR 평균: {np.mean(pred_psnrs):.2f}dB\")\n",
    "print(f\"Best T SSIM 평균: {np.mean(best_ssims):.4f}\")\n",
    "print(f\"Predicted T SSIM 평균: {np.mean(pred_ssims):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
